{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "print(sess.run(f))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    print(f.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(f.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "print(f.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the normal equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "housing_plus_offset = np.c_[np.ones((housing.data.shape[0], 1)), housing.data]\n",
    "X = tf.constant(housing_plus_offset, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_housing = StandardScaler().fit_transform(housing.data)\n",
    "scaled_offset_housing = np.c_[\n",
    "    np.ones((housing.data.shape[0], 1)), scaled_housing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the normal equation with scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0685577 ]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875156]\n",
      " [-0.26552734]\n",
      " [ 0.3056965 ]\n",
      " [-0.00450308]\n",
      " [-0.03932629]\n",
      " [-0.8998864 ]\n",
      " [-0.87054193]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual gradient decent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 9.413900375366211\n",
      "Epoch 1000, MSE 0.5294526219367981\n",
      "Epoch 2000, MSE 0.5245167016983032\n",
      "Epoch 3000, MSE 0.5243282318115234\n",
      "Epoch 4000, MSE 0.5243212580680847\n",
      "[[ 2.0685523 ]\n",
      " [ 0.8295648 ]\n",
      " [ 0.11878298]\n",
      " [-0.26534548]\n",
      " [ 0.30551198]\n",
      " [-0.00449096]\n",
      " [-0.03932773]\n",
      " [-0.8997085 ]\n",
      " [-0.8703533 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y= tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/housing.data.shape[0] * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, mse.eval()))\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using autodiff for the gradients..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 5.8281569480896\n",
      "Epoch 1000, MSE 0.5374355316162109\n",
      "Epoch 2000, MSE 0.5248290300369263\n",
      "Epoch 3000, MSE 0.5243416428565979\n",
      "Epoch 4000, MSE 0.5243220925331116\n",
      "[[ 2.0685525 ]\n",
      " [ 0.82975656]\n",
      " [ 0.1188428 ]\n",
      " [-0.26566607]\n",
      " [ 0.30575782]\n",
      " [-0.00447162]\n",
      " [-0.03933699]\n",
      " [-0.8990903 ]\n",
      " [-0.86975586]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y= tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, mse.eval()))\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the builtin gradient descent optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 9.966286659240723\n",
      "Epoch 1000, MSE 0.5459184050559998\n",
      "Epoch 2000, MSE 0.5256495475769043\n",
      "Epoch 3000, MSE 0.5244531631469727\n",
      "Epoch 4000, MSE 0.5243389010429382\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8313976 ]\n",
      " [ 0.11915641]\n",
      " [-0.26875275]\n",
      " [ 0.30830505]\n",
      " [-0.00437884]\n",
      " [-0.03939844]\n",
      " [-0.8952657 ]\n",
      " [-0.8661216 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y= tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, mse.eval()))\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a momentum optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 6.115485668182373\n",
      "Epoch 1000, MSE 0.5243209600448608\n",
      "Epoch 2000, MSE 0.5243209600448608\n",
      "Epoch 3000, MSE 0.5243209600448608\n",
      "Epoch 4000, MSE 0.5243209600448608\n",
      "[[ 2.0685577 ]\n",
      " [ 0.8296182 ]\n",
      " [ 0.11875145]\n",
      " [-0.265525  ]\n",
      " [ 0.3056947 ]\n",
      " [-0.00450307]\n",
      " [-0.03932623]\n",
      " [-0.899888  ]\n",
      " [-0.8705432 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y= tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, mse.eval()))\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_1 = B.eval(feed_dict={ A: [[1, 2, 3]] })\n",
    "    B_2 = B.eval(feed_dict={ A: [[4, 5, 6], [7, 8, 9]] })\n",
    "    \n",
    "print(\"{0}\\n{1}\".format(B_1, B_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 0\n",
      "Epoch 1000, MSE 0\n",
      "Epoch 2000, MSE 0\n",
      "Epoch 3000, MSE 0\n",
      "Epoch 4000, MSE 0\n",
      "[[ 2.04163623e+00]\n",
      " [ 7.76685953e-01]\n",
      " [ 1.02068946e-01]\n",
      " [-1.75507620e-01]\n",
      " [ 2.32567772e-01]\n",
      " [-8.55466409e-04]\n",
      " [-4.33079973e-02]\n",
      " [-8.76474440e-01]\n",
      " [-8.66599262e-01]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "batch_size = 10000\n",
    "num_batches = int(np.ceil(housing.data.shape[0] / batch_size))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(shape=(None, housing.data.shape[1] + 1),\n",
    "    dtype=tf.float32, name=\"X\")\n",
    "y= tf.placeholder(shape=(None, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    start = batch_index * batch_size\n",
    "    end = np.min([(batch_index + 1) * batch_size,\n",
    "                  scaled_offset_housing.shape[0]])\n",
    "    return (scaled_offset_housing[start:end, :], \n",
    "            housing.target.reshape(-1, 1)[start:end,:])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_index in range(num_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, 0))#mse.eval()))\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 9.707866668701172\n",
      "Epoch 1000, MSE 0.5390802621841431\n",
      "Epoch 2000, MSE 0.5266116857528687\n",
      "Epoch 3000, MSE 0.5246871113777161\n",
      "Epoch 4000, MSE 0.5243797898292542\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8330944 ]\n",
      " [ 0.11941039]\n",
      " [-0.27207884]\n",
      " [ 0.31110823]\n",
      " [-0.00430847]\n",
      " [-0.0394561 ]\n",
      " [-0.89182055]\n",
      " [-0.86287963]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y= tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() # create saver after all of the variables have been created\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, mse.eval()))\n",
    "            saver.save(sess, \"/tmp/tf.ckpt\")\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    saver.save(sess, \"/tmp/tf_final.ckpt\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tf_final.ckpt\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8330944 ]\n",
      " [ 0.11941039]\n",
      " [-0.27207884]\n",
      " [ 0.31110823]\n",
      " [-0.00430847]\n",
      " [-0.0394561 ]\n",
      " [-0.89182055]\n",
      " [-0.86287963]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/tf_final.ckpt\")\n",
    "    print(theta.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to log the error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 11.783705711364746\n",
      "Epoch 1000, MSE 0.5262514352798462\n",
      "Epoch 2000, MSE 0.5244504809379578\n",
      "Epoch 3000, MSE 0.5243350267410278\n",
      "Epoch 4000, MSE 0.5243229269981384\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logdir = \"/tmp/tf/run-{}\".format(datetime.utcnow().isoformat())\n",
    "\n",
    "n_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y= tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            summary_str = mse_summary.eval()\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, mse.eval()))\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some scope to the error and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 10.312064170837402\n",
      "Epoch 1000, MSE 0.5264008045196533\n",
      "Epoch 2000, MSE 0.5245612263679504\n",
      "Epoch 3000, MSE 0.5243558287620544\n",
      "Epoch 4000, MSE 0.5243263840675354\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logdir = \"/tmp/tf/run-{}\".format(datetime.utcnow().isoformat())\n",
    "\n",
    "n_epochs = 5000\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_offset_housing, dtype=tf.float32, name=\"X\")\n",
    "y= tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform([housing.data.shape[1] + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            summary_str = mse_summary.eval()\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch {0}, MSE {1}\".format(epoch, mse.eval()))\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (jupyter env)",
   "language": "python",
   "name": "jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
