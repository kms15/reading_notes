{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b2bf2c-d407-4385-81d0-ed858e1cc502",
   "metadata": {},
   "source": [
    "# Notes on Chapter 12 of *Hands-On Machine Learning with Scikit-Learn, Keras, & TensorFlow*, 3rd edition, by Aurélien Géron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea82cd-5344-477f-b81a-d966620671af",
   "metadata": {},
   "source": [
    "Reduce the amount of logging messages displayed by TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466eee58-3312-4170-8a5f-ebb7c1ed3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b720138c-afe5-43f6-8895-372c7d10f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbfa452-a952-4247-9141-71b9ab11a2ff",
   "metadata": {},
   "source": [
    "## Basic tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f580313d-986d-49fa-bc08-48b205f8e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1,2],[3,4],[5,6]], dtype=tf.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920e26c2-9177-474e-aceb-ee7ba2ff167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d28ad5-97e4-4421-b498-43eda0583194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[ 3.,  6.],\n",
       "       [ 9., 12.],\n",
       "       [15., 18.]], dtype=float16)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87493fc-25ca-4c80-8a26-7089fc0554c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float16, numpy=\n",
       "array([[ 5., 11., 17.],\n",
       "       [11., 25., 39.],\n",
       "       [17., 39., 61.]], dtype=float16)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ tf.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba58bfbf-75b9-447b-9bfa-387fb4cc5a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=23>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f6ca2-b195-4ae9-8e68-8dd9c7600088",
   "metadata": {},
   "source": [
    "Keras 3 also has a tensor library in keras.ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297da91d-5b4c-4a9d-958f-b4470549270a",
   "metadata": {},
   "source": [
    "```\n",
    "y = keras.ops.array([[1,2],[3,4],[5,6]])\n",
    "y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98024f8b-bbe5-4782-8e51-e774da80d2a7",
   "metadata": {},
   "source": [
    "```\n",
    "[[1,2],[3,4],[5,6]] * keras.ops.arange(2,4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9077f-8857-4788-aa37-4940e6d35ce3",
   "metadata": {},
   "source": [
    "Note the tensorflow will not automatically perform implicit type promotion due to performance concerns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36cea1be-6d75-4ccc-b56d-278ad9f774bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'> : cannot compute Mul as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Mul] name: \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(3) * tf.constant(2.)\n",
    "except Exception as e:\n",
    "    print(type(e), ':', e)\n",
    "else:\n",
    "    assert False # (unreached)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb0c9f-f4a7-410a-be49-94cd1e2a4442",
   "metadata": {},
   "source": [
    "Thus manual casts are required for this type of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecda18eb-deeb-428d-8cd3-08a13596db23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.constant(3), tf.float32) * tf.constant(2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c445706-b191-4f8f-b82e-38bdd00813e9",
   "metadata": {},
   "source": [
    "Tensorflow also includes a more comprehensive numpy emulation library in experimental. First one needs to enable Numpy-like behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b018a8-e3aa-41f3-9aad-13c49c1932b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d458d-7d42-437f-a103-c529bc632173",
   "metadata": {},
   "source": [
    "This enables automatic type promotion, in addition to adding more numpy-like member functions (e.g. ravel and reshape) to tf tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a75033-994a-42d9-a94a-5428aa2d44b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=6.0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(3) * tf.constant(2.) # previously an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d5afb2-f51b-4eed-9a95-2084489e80e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int64, numpy=\n",
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tnp.arange(12).reshape((3,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea234a50-8f69-4e05-ae11-6faf1455051f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[4, 5, 6, 7]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[tnp.newaxis, 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0597f90-fe90-4909-b1c5-6ec059994101",
   "metadata": {},
   "source": [
    "Note that (unlike JAX) some things like direct assignment are still not allowed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e11effa-9e33-47b6-a691-9127a2804527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'TypeError'> : 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x[1,1] = 100\n",
    "except Exception as e:\n",
    "    print(type(e), ':', e)\n",
    "else:\n",
    "    assert False # (unreached)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e4ccc-7550-4a6c-b487-3b2221b0a582",
   "metadata": {},
   "source": [
    "Mutible tensors need to be declared with tf.Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e93fc0b-119a-45dc-8815-62e6bc044a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "572580c6-2e96-47b7-9ecc-f9aa0b68e15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
       "array([[2, 4],\n",
       "       [6, 8]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign( 2*x )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b76a8d47-ebde-48f5-af56-b610276bc9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
       "array([[23,  4],\n",
       "       [ 6, 42]], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.scatter_nd_update([[0,0], [1,1,]], [23, 42])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e1d19-e3ff-491f-bff9-63f653f95b29",
   "metadata": {},
   "source": [
    "### Custom objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298e893-53d5-4331-9e46-5c424de7a657",
   "metadata": {},
   "source": [
    "Custom objects such as loss functions can be used, but they can create complications when loading and saving models. In particular, you'll need to provide a dictionary at load time with the custom components, which can be either functions or objects that implement a get_config function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f98ac50-f35e-4c72-a43f-8fb71368b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.models.Sequential([\n",
    "    layers.Input((8,)),\n",
    "    layers.Dense(12),\n",
    "    layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "845182e8-84b3-4f16-b42e-c2515028916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_predicted):\n",
    "    residual = y_true - y_predicted\n",
    "    return tf.where(tf.abs(residual) > 1, residual, tf.square(residual)/2)\n",
    "\n",
    "class MyLRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, alpha, **kwargs):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.alpha = alpha\n",
    "        super().__init__(**kwargs) # kwargs not needed for this example\n",
    "\n",
    "    def __call__(self, step):\n",
    "        return self.initial_learning_rate / (step + 1)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = {} #super().get_config()\n",
    "        return {\n",
    "            'initial_learning_rate': self.initial_learning_rate,\n",
    "            'alpha': self.alpha,\n",
    "            **base_config,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d6cb567-831d-4493-8b67-16ea1d856564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711765640.283118  582241 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "m.compile(\n",
    "    loss=my_loss,\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=MyLRSchedule(0.002, 0.999))\n",
    ")\n",
    "m.fit(tf.constant([[1,2,3,4,5,6,7,8]]), tf.constant([1]), verbose=0)\n",
    "m.save('ch13_custom_objects.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153faa4-94d0-4ee4-9806-03255435d281",
   "metadata": {},
   "source": [
    "Load will fail without custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26602d71-814f-4281-97df-a9d7d3b3a3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'TypeError'> Cannot deserialize object of type `MyLRSchedule`. If `MyLRSchedule` is a custom class, please register it using the `@keras.saving.register_keras_serializable()` decorator.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    m1 = keras.models.load_model('ch13_custom_objects.keras')\n",
    "    assert False # unreached\n",
    "except TypeError as e:\n",
    "    print(type(e), e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b74822-28ed-41f5-81e9-4a8115ba4823",
   "metadata": {},
   "source": [
    "Custom objects can be passed either as a context or an extra parameters on load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c4d70c-946d-471b-bb58-2e36ccede1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {\n",
    "    'my_loss': my_loss,\n",
    "    'MyLRSchedule': MyLRSchedule\n",
    "}\n",
    "\n",
    "m1 = tf.keras.models.load_model(\n",
    "    'ch13_custom_objects.keras',\n",
    "    custom_objects=custom_objects\n",
    ")\n",
    "\n",
    "with keras.saving.custom_object_scope(custom_objects):\n",
    "    m2 = tf.keras.models.load_model('ch13_custom_objects.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1b22e-8179-4a86-a18d-5d9703ef5a46",
   "metadata": {},
   "source": [
    "Custom layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10fc24-e06b-4b95-b2c9-14433d6ea37f",
   "metadata": {},
   "source": [
    "Simple layers without weights can be constructed with a lambda layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ef34a15-537a-4041-9ca2-972d4aa08caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_layer = keras.layers.Lambda(lambda x : tf.square(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0a290-a45f-4711-9b61-20665b18c897",
   "metadata": {},
   "source": [
    "More complex layers can be implemented by deriving from the Layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c01a88d-0abd-4c93-896d-9feda93da711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseAndFlatten(layers.Layer):\n",
    "    \"\"\"Same as the old Dense, but with less functionality\"\"\"\n",
    "    \n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    # initialize the parameters etc the first time this instance is used.\n",
    "    def build(self, batch_input_shape):\n",
    "        self.W = self.add_weight(name=\"W\", shape=(batch_input_shape[-1], self.units),\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.b = self.add_weight(name=\"b\", shape=(self.units,),\n",
    "            initializer=\"zeros\")\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.W + self.b)\n",
    "\n",
    "    def get_config(self):\n",
    "        # needed only if supporting load/save functionality\n",
    "        return {\n",
    "            \"units\": self.units,\n",
    "            \"activation\": keras.activations.serialize(self.activation),\n",
    "            **(super().get_config())\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64dafde-4ee8-40f3-ad80-b4883078ee7a",
   "metadata": {},
   "source": [
    "Models are a subclass of layers and custom layers can be defined in a similar fashion. This can sometimes be useful when a loss function needs to contain a term from internal variables in the model, in which case you can call the Model.add_loss to add a term to the loss function (typically as part of the call function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84784492-48f6-4336-ac60-b69aeec097bc",
   "metadata": {},
   "source": [
    "## GradientTape and Autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a338a-a245-41f3-8967-89bbc9edb565",
   "metadata": {},
   "source": [
    "The GradientTape class can be used to record autodiff-calculated gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d658599-3aba-4c98-b936-01bf89ed8f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=24.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=40.0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x,y):\n",
    "    return x - 2*y + x*y\n",
    "\n",
    "x1 = tf.Variable(42.)\n",
    "y1 = tf.Variable(23.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(x1, y1)\n",
    "\n",
    "tape.gradient(z1, [x1, y1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39743a1-981d-4d1e-8aa7-4a7aa4b024f8",
   "metadata": {},
   "source": [
    "By default gradient tapes can only be queried once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc51ecc6-5758-44e2-98fa-fa71b28a04fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.0, shape=(), dtype=float32)\n",
      "<class 'RuntimeError'> : A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(x1, y1)\n",
    "\n",
    "print(tape.gradient(z1, x1))\n",
    "\n",
    "try:\n",
    "    print(tape.gradient(z1, y1))\n",
    "except RuntimeError as e:\n",
    "    print(type(e), ':', e)\n",
    "else:\n",
    "    assert False # (unreached)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8cad5e-652b-4b38-a5a6-80f9063ebe55",
   "metadata": {},
   "source": [
    "This behavior can be controlled with the `persistent` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fad54b0-cfe5-4c1e-8bb4-c6958b7ab907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.0, shape=(), dtype=float32)\n",
      "tf.Tensor(40.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(x1, y1)\n",
    "\n",
    "print(tape.gradient(z1, x1))\n",
    "print(tape.gradient(z1, y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f0cd2-6a3a-416c-8c6d-9703e3439ad3",
   "metadata": {},
   "source": [
    "Only variables are tracked by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3e87594-adff-4152-be77-a1efc4a1f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "c1 = tf.constant(7.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = c1 * f(x1, y1)\n",
    "\n",
    "print(tape.gradient(z1, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb93032-2fb9-4255-9f61-b676ce43f562",
   "metadata": {},
   "source": [
    "Things like constants can be tracked by adding them with the `watch` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53d0b025-c10b-4968-bebf-e6f2a2ccdde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(962.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    z1 = c1 * f(x1, y1)\n",
    "\n",
    "print(tape.gradient(z1, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a902da0-6787-454f-a8b2-580653616a41",
   "metadata": {},
   "source": [
    "### Custom training loops\n",
    "\n",
    "We can easily create custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bdfa5b2-8d7c-4783-b994-5e9bec415b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cb802f1-de80-40bb-b335-7a3dfc6a79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.Sequential([\n",
    "    layers.Input(shape=(28,28)),\n",
    "    layers.Reshape((28,28,1)),\n",
    "    layers.Conv2D(8, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(16, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Dense(10),\n",
    "    layers.Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8f6a575-354c-4bda-809e-63f0aa891afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "optimizer = keras.optimizers.AdamW()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "mean_loss_train = keras.metrics.Mean(name=\"mean_loss_train\")\n",
    "mean_loss_val = keras.metrics.Mean(name=\"mean_loss_val\")\n",
    "metrics_train = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "metrics_val = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "372e3230-d96c-41c3-bc79-109b911c242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fd7effa44c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fd7effa44c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch:0 loss_train:4.724 sparse_categorical_accuracy_train:0.757 loss_val:0.570 sparse_categorical_accuracy_val:0.875\n",
      "Epoch:1 loss_train:2.558 sparse_categorical_accuracy_train:0.908 loss_val:0.429 sparse_categorical_accuracy_val:0.926\n",
      "Epoch:2 loss_train:1.781 sparse_categorical_accuracy_train:0.940 loss_val:0.351 sparse_categorical_accuracy_val:0.947\n",
      "Epoch:3 loss_train:1.374 sparse_categorical_accuracy_train:0.957 loss_val:0.301 sparse_categorical_accuracy_val:0.956\n",
      "Epoch:4 loss_train:1.122 sparse_categorical_accuracy_train:0.967 loss_val:0.267 sparse_categorical_accuracy_val:0.964\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_hat_batch = m(X_batch, training=True)\n",
    "            loss = tf.reduce_mean(loss_fn(y_batch, y_hat_batch))\n",
    "        gradients = tape.gradient(loss, m.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, m.trainable_variables))\n",
    "        mean_loss_train(loss)\n",
    "        for metric in metrics_train:\n",
    "            metric(y_batch, y_hat_batch)\n",
    "    \n",
    "    for i in range(0, X_test.shape[0], batch_size):\n",
    "        X_batch = X_test[i:i+batch_size]\n",
    "        y_batch = y_test[i:i+batch_size]\n",
    "        y_hat_batch = m(X_batch)\n",
    "        loss = tf.reduce_mean(loss_fn(y_batch, y_hat_batch))\n",
    "        mean_loss_val(loss)\n",
    "        for metric in metrics_val:\n",
    "            metric(y_batch, y_hat_batch)\n",
    "        \n",
    "    \n",
    "    print(\n",
    "        f\"Epoch:{epoch}\"\n",
    "        + f\" loss_train:{mean_loss_train.result():.3f} \"\n",
    "        + \" \".join([\n",
    "                f\"{metric.name}_train:{metric.result():.3f}\" for metric in metrics_train\n",
    "            ])\n",
    "        + f\" loss_val:{mean_loss_val.result():.3f} \"\n",
    "        + \" \".join([\n",
    "                f\"{metric.name}_val:{metric.result():.3f}\" for metric in metrics_val\n",
    "            ])\n",
    "    )\n",
    "            \n",
    "    for metric in metrics_train + metrics_val:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e84302-20a4-4ef0-9d34-7b980578e81b",
   "metadata": {},
   "source": [
    "### Tensorflow graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d05a8-7e81-4ea2-8732-38a53c518865",
   "metadata": {},
   "source": [
    "A function can be converted to a Tensorflow graph using tf.function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77b8214d-d116-4354-8a82-007e3306e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_python_func(n):\n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += (-n)**3\n",
    "    return result\n",
    "\n",
    "my_tf_func = tf.function(my_python_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6095006a-484a-4f08-bec0-c5a9383c44f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4096"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_python_func(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a26744e-06ea-44b9-b254-4c47a1eb6624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=-4096>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tf_func(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49406dc0-6aab-4dbd-802d-bcabaaa23a6e",
   "metadata": {},
   "source": [
    "Underneath the hood, the function is first converted to a control-statement-free form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcf9d3bb-fa06-4c8c-b65b-39ab282133a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__my_python_func(n):\n",
      "    with ag__.FunctionScope('my_python_func', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        result = 0\n",
      "\n",
      "        def get_state():\n",
      "            return (result,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal result\n",
      "            (result,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal result\n",
      "            i = itr\n",
      "            result = ag__.ld(result)\n",
      "            result += (-n) ** 3\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(n),), None, fscope), None, loop_body, get_state, set_state, ('result',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(result)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(my_python_func))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de2214-f0a1-435a-be0f-7b3a8161372e",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ca2b7-30ac-4e2d-a0e5-07ab3468f910",
   "metadata": {},
   "source": [
    "### 12.1\n",
    "\n",
    "Tensorflow is a framework for performing efficient calculations on multidimensional arrays with an extensive set of tools for building neural networks built on these arrays. Other similar popular libraries include PyTorch and JAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dba5ff-d13b-487f-a8b3-657842abc77d",
   "metadata": {},
   "source": [
    "### 12.2\n",
    "\n",
    "In most cases Tensorflow and Numpy can be used for the same tasks, but in many cases they do not use identical syntax so they are usually not drop-in replacements for one another. Tensorflow tends to be more performant but less widely supported. Numpy also lacks features such as autodiff and pre-built neural network abstractions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20864cb5-3e92-4a78-a093-fc8912f35c89",
   "metadata": {},
   "source": [
    "### 12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18d312a2-9221-48af-b1cd-71dcbcd0226f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "323449d9-d2d2-4360-86da-bf60278cb504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35266dff-2e2e-4019-88bf-443edec9ca7f",
   "metadata": {},
   "source": [
    "Note the differences in default integer size, and also that the latter will not work properly with autograph or autodiff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a7194-7bf3-4c47-b1fb-accf69e6f1d0",
   "metadata": {},
   "source": [
    "### 12.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "847711dc-68f7-4eab-a2c6-fb1f8c094cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62068a53-f401-4104-9151-894390e56dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0, 1, 2], [3]]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.RaggedTensor.from_row_lengths(range(4), [3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b13e8640-7f52-474b-af89-be82548d3c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[1 1]\n",
       " [2 3]], shape=(2, 2), dtype=int64), values=tf.Tensor([7 8], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.SparseTensor([[1,1],[2,3]], [7,8], [3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "709b95e2-f8fa-488f-856d-ed527baefbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.backprop.GradientTape at 0x7fd9d5bc63b0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.GradientTape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db2c380b-17ff-41d0-b9a7-c80ea8130db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7fd8167b7a30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4939c1a-a991-44a3-8554-38029348bc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x7fd816584ee0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.TensorArray(tf.float32, size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030c5eb-1ced-4b82-ac26-58727c2afd4f",
   "metadata": {},
   "source": [
    "### 12.5\n",
    "\n",
    "As is typical for callable objects, the choice between a function and a class is usually based on whether one need state that will persist across multiple calls to the callable object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdd706-3b76-4d5a-9959-6d9e063450c8",
   "metadata": {},
   "source": [
    "### 12.6\n",
    "\n",
    "See 12.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f624f-c12a-40db-af70-5995a7bc7968",
   "metadata": {},
   "source": [
    "### 12.7\n",
    "\n",
    "Although custom models are a subclass of layers (and will work as one), it's best to reserve custom models for capturing the behavior of the model as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c0a53-3274-4c3e-a3e0-7a3faefaa5d0",
   "metadata": {},
   "source": [
    "### 12.8\n",
    "\n",
    "Models that require more detailed control than is available in the standard training loop, e.g. the use of different optimizers in different parts of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f9bfb-0a16-45d1-92d7-0663829a1f1a",
   "metadata": {},
   "source": [
    "### 12.9\n",
    "\n",
    "They usually can contain arbitrary python code, but performance may be poor compared to code that could be converted by autograph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9824d-600d-4e1b-9f6c-7c240bef8436",
   "metadata": {},
   "source": [
    "### 12.10\n",
    "\n",
    "- External library code may only be called during tracing, so avoid this if possible (and plan carefully when not)\n",
    "- For loops will only run during tracing in most circumstances (exceptions include looping over tensors or datasets)\n",
    "- Variable creation will only occur during tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e8cf7-298c-4397-a456-710657c23c23",
   "metadata": {},
   "source": [
    "### 12.11\n",
    "\n",
    "A dynamic keras model may be needed when the model can change during training, e.g. adding or removing layers. One approach to this would use a custom training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3169dde4-78c1-4a9a-a862-658640d78957",
   "metadata": {},
   "source": [
    "### 12.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09fda123-3d69-4577-ad3e-05f45f69cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(layers.Layer):\n",
    "    \"\"\"Same as the old Dense, but with less functionality\"\"\"\n",
    "    \n",
    "    def __init__(self, epsilon=1e-3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = tf.constant(epsilon)\n",
    "\n",
    "    # initialize the parameters etc the first time this instance is used.\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name=\"alpha\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"ones\")\n",
    "        self.beta = self.add_weight(name=\"beta\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"zeros\")\n",
    "\n",
    "    def call(self, X):\n",
    "        mu, sigma_squared = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        sigma = tf.math.sqrt(sigma_squared)\n",
    "        return self.alpha * (X - mu) / (sigma + self.epsilon) + self.beta\n",
    "\n",
    "    def get_config(self):\n",
    "        # needed only if supporting load/save functionality\n",
    "        return {\n",
    "            \"epsilon\": self.epsilon,\n",
    "            **(super().get_config())\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "664f46b3-e4c7-437e-99f5-174435e32bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.2232468   0.          1.2232468 ]\n",
      " [-1.0686165  -0.26715407  1.3357707 ]], shape=(2, 3), dtype=float32) tf.Tensor(\n",
      "[[-1.2238274   0.          1.2238274 ]\n",
      " [-1.0689592  -0.26723987  1.3361988 ]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "l1 = LayerNormalization()\n",
    "l2 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "l1.build(tf.constant((2,3)))\n",
    "l2.build(tf.constant((2,3)))\n",
    "\n",
    "X = tf.constant([[1,2,3],[5,7,11]], dtype=float)\n",
    "print(l1(X), l2(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3899cf0-1eea-4bc1-9cc0-30bc5abd9514",
   "metadata": {},
   "source": [
    "### 12.13\n",
    "#### 12.13.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77ca5282-5aa9-42c2-a185-50cb8bd7e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test,y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef0f5ec6-0ed5-404a-92b6-c25dd3f97e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.Sequential([\n",
    "    layers.Input(shape=(28,28)),\n",
    "    layers.Reshape((28,28,1)),\n",
    "    layers.Conv2D(8, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(16, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Dense(10),\n",
    "    layers.Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "637341f6-1fea-4972-b782-e5cd8e1632d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "optimizer = keras.optimizers.AdamW()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "mean_loss_train = keras.metrics.Mean(name=\"mean_loss_train\")\n",
    "mean_loss_val = keras.metrics.Mean(name=\"mean_loss_val\")\n",
    "metrics_train = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "metrics_val = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43a0f64d-016c-41cf-8314-c99e95120016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 loss_train:2.939 sparse_categorical_accuracy_train:0.714 loss_val:0.686 sparse_categorical_accuracy_val:0.788\n",
      "Epoch:1 loss_train:1.745 sparse_categorical_accuracy_train:0.816 loss_val:0.614 sparse_categorical_accuracy_val:0.817\n",
      "Epoch:2 loss_train:1.313 sparse_categorical_accuracy_train:0.844 loss_val:0.571 sparse_categorical_accuracy_val:0.835\n",
      "Epoch:3 loss_train:1.084 sparse_categorical_accuracy_train:0.859 loss_val:0.541 sparse_categorical_accuracy_val:0.844\n",
      "Epoch:4 loss_train:0.940 sparse_categorical_accuracy_train:0.870 loss_val:0.520 sparse_categorical_accuracy_val:0.849\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_hat_batch = m(X_batch, training=True)\n",
    "            loss = tf.reduce_mean(loss_fn(y_batch, y_hat_batch))\n",
    "        gradients = tape.gradient(loss, m.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, m.trainable_variables))\n",
    "        mean_loss_train(loss)\n",
    "        for metric in metrics_train:\n",
    "            metric(y_batch, y_hat_batch)\n",
    "        print(\n",
    "            f\"Epoch:{epoch}\"\n",
    "            + f\" {100*i/X_train.shape[0]:5.2f}% \"\n",
    "            + f\" loss_train:{mean_loss_train.result():5.3f} \"\n",
    "            + \" \".join([\n",
    "                f\"{metric.name}_train:{metric.result():.3f}\" for metric in metrics_train\n",
    "            ]),\n",
    "            end=\"\\r\"\n",
    "        )\n",
    "    \n",
    "    for i in range(0, X_test.shape[0], batch_size):\n",
    "        X_batch = X_test[i:i+batch_size]\n",
    "        y_batch = y_test[i:i+batch_size]\n",
    "        y_hat_batch = m(X_batch)\n",
    "        loss = tf.reduce_mean(loss_fn(y_batch, y_hat_batch))\n",
    "        mean_loss_val(loss)\n",
    "        for metric in metrics_val:\n",
    "            metric(y_batch, y_hat_batch)\n",
    "        \n",
    "    \n",
    "    print(\n",
    "        f\"Epoch:{epoch}\"\n",
    "        + f\" loss_train:{mean_loss_train.result():.3f} \"\n",
    "        + \" \".join([\n",
    "                f\"{metric.name}_train:{metric.result():.3f}\" for metric in metrics_train\n",
    "            ])\n",
    "        + f\" loss_val:{mean_loss_val.result():.3f} \"\n",
    "        + \" \".join([\n",
    "                f\"{metric.name}_val:{metric.result():.3f}\" for metric in metrics_val\n",
    "            ])\n",
    "    )\n",
    "            \n",
    "    for metric in metrics_train + metrics_val:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1cca9-9943-453d-b3db-c9a1cf7780ab",
   "metadata": {},
   "source": [
    "### 12.13\n",
    "#### 12.13.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9c82694-13ec-41f0-8a99-07f5007ace5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test,y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "debf35eb-3101-4d4e-a657-fa378531482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = keras.Sequential([\n",
    "    layers.Conv2D(8, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(16, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32, (5,5), padding=\"same\", kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.MaxPool2D(),\n",
    "])\n",
    "\n",
    "upper = keras.Sequential([\n",
    "    layers.Dense(32, kernel_initializer=\"he_uniform\"),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Dense(10),\n",
    "    layers.Activation('softmax'),\n",
    "])\n",
    "\n",
    "m = keras.Sequential([\n",
    "    layers.Input(shape=(28,28)),\n",
    "    layers.Reshape((28,28,1)),\n",
    "    lower,\n",
    "    layers.Flatten(),\n",
    "    upper,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eaec7507-13ce-4965-b7ee-45fcc8ad6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "optimizer_lower = keras.optimizers.AdamW()\n",
    "optimizer_upper = keras.optimizers.Adam(learning_rate=0.002)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "mean_loss_train = keras.metrics.Mean(name=\"mean_loss_train\")\n",
    "mean_loss_val = keras.metrics.Mean(name=\"mean_loss_val\")\n",
    "metrics_train = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "metrics_val = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "935424f0-23a5-4041-bb4a-56b6991630f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 loss_train:4.567 sparse_categorical_accuracy_train:0.680 loss_val:0.735 sparse_categorical_accuracy_val:0.761\n",
      "Epoch:1 loss_train:2.579 sparse_categorical_accuracy_train:0.798 loss_val:0.657 sparse_categorical_accuracy_val:0.797\n",
      "Epoch:2 loss_train:1.882 sparse_categorical_accuracy_train:0.829 loss_val:0.607 sparse_categorical_accuracy_val:0.817\n",
      "Epoch:3 loss_train:1.519 sparse_categorical_accuracy_train:0.846 loss_val:0.571 sparse_categorical_accuracy_val:0.834\n",
      "Epoch:4 loss_train:1.295 sparse_categorical_accuracy_train:0.860 loss_val:0.545 sparse_categorical_accuracy_val:0.843\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            y_hat_batch = m(X_batch, training=True)\n",
    "            loss = tf.reduce_mean(loss_fn(y_batch, y_hat_batch))\n",
    "        gradients_lower = tape.gradient(loss, lower.trainable_variables)\n",
    "        optimizer_lower.apply_gradients(zip(gradients_lower, lower.trainable_variables))\n",
    "        gradients_upper = tape.gradient(loss, upper.trainable_variables)\n",
    "        optimizer_upper.apply_gradients(zip(gradients_upper, upper.trainable_variables))\n",
    "        mean_loss_train(loss)\n",
    "        for metric in metrics_train:\n",
    "            metric(y_batch, y_hat_batch)\n",
    "        print(\n",
    "            f\"Epoch:{epoch}\"\n",
    "            + f\" {100*i/X_train.shape[0]:5.2f}% \"\n",
    "            + f\" loss_train:{mean_loss_train.result():5.3f} \"\n",
    "            + \" \".join([\n",
    "                f\"{metric.name}_train:{metric.result():.3f}\" for metric in metrics_train\n",
    "            ]),\n",
    "            end=\"\\r\"\n",
    "        )\n",
    "    \n",
    "    for i in range(0, X_test.shape[0], batch_size):\n",
    "        X_batch = X_test[i:i+batch_size]\n",
    "        y_batch = y_test[i:i+batch_size]\n",
    "        y_hat_batch = m(X_batch)\n",
    "        loss = tf.reduce_mean(loss_fn(y_batch, y_hat_batch))\n",
    "        mean_loss_val(loss)\n",
    "        for metric in metrics_val:\n",
    "            metric(y_batch, y_hat_batch)\n",
    "        \n",
    "    \n",
    "    print(\n",
    "        f\"Epoch:{epoch}\"\n",
    "        + f\" loss_train:{mean_loss_train.result():.3f} \"\n",
    "        + \" \".join([\n",
    "                f\"{metric.name}_train:{metric.result():.3f}\" for metric in metrics_train\n",
    "            ])\n",
    "        + f\" loss_val:{mean_loss_val.result():.3f} \"\n",
    "        + \" \".join([\n",
    "                f\"{metric.name}_val:{metric.result():.3f}\" for metric in metrics_val\n",
    "            ])\n",
    "    )\n",
    "            \n",
    "    for metric in metrics_train + metrics_val:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631c24d-2b2e-4dd2-9f67-7fe9f67508e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
