{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff01131-34f7-497f-a63c-fb9074575b7b",
   "metadata": {},
   "source": [
    "# Notes on Chapter 13 of *Hands-On Machine Learning with Scikit-Learn, Keras, & TensorFlow*, 3rd edition, by Aurélien Géron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a45719-b3ae-4445-aa87-b27fed7b229d",
   "metadata": {},
   "source": [
    "Reduce the amount of logging messages displayed by TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211f35b0-466b-4fef-bf82-acae3b4657c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f417a46-da24-486f-9dc2-e19e2b7c00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d912d5c-063c-47f0-8388-4380001b8896",
   "metadata": {},
   "source": [
    "Datasets are iterable sequences of data items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "887a9d77-2026-4395-a648-9b31a9a7814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 2.], dtype=float32)>, 'b': <tf.Tensor: shape=(), dtype=float32, numpy=100.0>}\n",
      "{'a': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([3., 4., 5.], dtype=float32)>, 'b': <tf.Tensor: shape=(), dtype=float32, numpy=101.0>}\n",
      "{'a': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([6., 7., 8.], dtype=float32)>, 'b': <tf.Tensor: shape=(), dtype=float32, numpy=102.0>}\n"
     ]
    }
   ],
   "source": [
    "X = {\"a\" : tf.reshape(tf.range(9.), (3,3)), \"b\": tf.range(100.,103)}\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "for x in dataset:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2bb46-e5c3-4b69-9fd1-0f3c2dc3b683",
   "metadata": {},
   "source": [
    "Multiple transformations can be chained together on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92e9e8f4-1e81-45c0-99bb-ae03f64781f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': <tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
      "array([[108.1, 109.1, 110.1],\n",
      "       [104.1, 105.1, 106.1],\n",
      "       [100.1, 101.1, 102.1],\n",
      "       [104.1, 105.1, 106.1]], dtype=float32)>, 'd': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([204., 202., 200., 202.], dtype=float32)>}\n",
      "{'c': <tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
      "array([[100.1, 101.1, 102.1],\n",
      "       [100.1, 101.1, 102.1],\n",
      "       [108.1, 109.1, 110.1],\n",
      "       [104.1, 105.1, 106.1]], dtype=float32)>, 'd': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([200., 200., 204., 202.], dtype=float32)>}\n",
      "{'c': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[108.1, 109.1, 110.1]], dtype=float32)>, 'd': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([204.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "dataset2 = dataset.repeat(3).map(\n",
    "        lambda x: {'c':x['a']+0.1+x['b'], 'd':2*x['b']}\n",
    "    ).shuffle(buffer_size=5, seed=13).batch(4)\n",
    "for x in dataset2:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb13212-bcbd-49ed-a2af-a7a5f6f23254",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0b591-e40b-4ce1-a02b-24d65b74d23e",
   "metadata": {},
   "source": [
    "### 13.1\n",
    "\n",
    "When datasets are large enough that loading and preprocessing of the data becomes a bottleneck, the tf.data api provides a performant way to take advantage of multiple threads, prefetching, and streaming of the data to reduce this bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385eb3f1-f017-4146-88a0-7405661085c6",
   "metadata": {},
   "source": [
    "### 13.2\n",
    "\n",
    "Splitting the data into multiple files uses the filesystem to provide a high level index into the dataset. This index allows easily jumping to different disjoint chunks of the dataset, and thus simplifies things like reading the data concurrently from multiple threads. While the filesystem may not be the most performant way to index the data like this (e.g. a nosql database can be faster), it's usually good enough and the many tools available for examining and debugging the filesystem can make it the best solution overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9ed88-36f3-456b-a5c2-ccc859a180af",
   "metadata": {},
   "source": [
    "### 13.3\n",
    "\n",
    "Profiling the code is the most reliably way of detecting bottlenecks. Like any bottleneck, one first needs to identify the limiting resource (e.g. CPU cycles, SSD bandwidth, etc) and then either reduce the resource demand (e.g. with a better algorithm or data format) or increase the amount of the resource (e.g. by switching to a multi-threaded setup, changing hardware, etc) and/or shift the demand to another resource (e.g. use unused CPU cycles while the GPU is training to prefetch the data rather than using more limited CPU cycles while the GPU is idle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689ce82-1da6-40c2-99c1-6113c2204e55",
   "metadata": {},
   "source": [
    "### 13.4\n",
    "\n",
    "You can save any data you like (within certain size limits) within a TFRecord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1445b-e1a0-4ff7-a4e5-a089070bbf7f",
   "metadata": {},
   "source": [
    "### 13.5\n",
    "\n",
    "Tensorflow provides a number of useful predefined parsing routines for the \n",
    "`Example` protobuf format, and replicating these routines (in a TensorFlow\n",
    "compatible and performant way) is often more work than just adapting to\n",
    "the `Example` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe416d1-c4e9-4a59-8ed5-2b86c164d3dd",
   "metadata": {},
   "source": [
    "### 13.6\n",
    "\n",
    "Compression makes sense when A) the data is compressible (e.g. not already in\n",
    "a compressed format like jpg), and B) space and/or bandwidth are more limiting\n",
    "than the CPU cycles required for compression/decompression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f01c50-cc4d-4fad-8e74-d59ebe6d3c16",
   "metadata": {},
   "source": [
    "### 13.7\n",
    "\n",
    "#### preprocessing when writing the files:\n",
    "##### pros:\n",
    "- preprocessing is performed once on data ingestion (most efficient)\n",
    "##### cons:\n",
    "- preprocessing code must be repeated in production/deployment of the model\n",
    "\n",
    "#### preprocessing within tf.data pipeline\n",
    "##### pros:\n",
    "- allows more dynamic changes (e.g. shuffling) during training\n",
    "- allows decompression during training\n",
    "##### cons:\n",
    "- preprocessing is repeated for every epoc of training\n",
    "\n",
    "#### preprocessing in the model\n",
    "##### pros:\n",
    "- Allows learning of details of preprocessing (e.g. embedding vectors)\n",
    "- Allows a unified approach to hyperparameter tuning\n",
    "##### cons:\n",
    "- complicates the model, embedding more assuptions about the data\n",
    "- some types of preprocessing (e.g. shuffling) are hard to implement well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c850258-b740-40e3-886c-e5ebf7f99e77",
   "metadata": {},
   "source": [
    "### 13.8\n",
    "\n",
    "For small cardinalities, categorical integer vectors are often encoded as one-hot vectors. They can also be encoded as a scaled float (which can be harder to learn). For larger cardinalities, embedding vectors are often used.\n",
    "\n",
    "For text, often it is encoded as a string of embedding vectors for each word/token, as sentence embedding vectors, or even document embedding vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9beb6-37ac-4bf9-bfe0-ec114e945d8a",
   "metadata": {},
   "source": [
    "### 13.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e95842-f768-489a-8540-bda976b88e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "shuffled_index = tf.random.shuffle(tf.range(x_train.shape[0] + x_test.shape[0]), seed=42)\n",
    "x = tf.gather(tf.concat([x_train, x_test], axis=0), shuffled_index)\n",
    "y = tf.gather(tf.concat([y_train, y_test], axis=0), shuffled_index)\n",
    "x_test, x_validation, x_train = x[:10000], x[10000:20000], x[20000:]\n",
    "y_test, y_validation, y_train = y[:10000], y[10000:20000], y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad37fe2-8819-41c7-b9d1-8e299a3cf215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50000, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d30ae2-b831-491a-9190-0bc716d6eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Randomly shuffles a tensor along its first dimension.\n",
       "\n",
       "The tensor is shuffled along dimension 0, such that each `value[j]` is mapped\n",
       "to one and only one `output[i]`. For example, a mapping that might occur for a\n",
       "3x2 tensor is:\n",
       "\n",
       "```python\n",
       "[[1, 2],       [[5, 6],\n",
       " [3, 4],  ==>   [1, 2],\n",
       " [5, 6]]        [3, 4]]\n",
       "```\n",
       "\n",
       "Args:\n",
       "  value: A Tensor to be shuffled.\n",
       "  seed: A Python integer. Used to create a random seed for the distribution.\n",
       "    See\n",
       "    `tf.random.set_seed`\n",
       "    for behavior.\n",
       "  name: A name for the operation (optional).\n",
       "\n",
       "Returns:\n",
       "  A tensor of same shape and type as `value`, shuffled along its first\n",
       "  dimension.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/random_ops.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tf.random.shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab7da67-337c-42c0-81e6-c2f5f4f7b8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([70000, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7c66f-a0c9-42e0-8797-a560155a9420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
